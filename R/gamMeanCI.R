# ####
#' Compute mean and confidence interval for x-year period based on GAM results
#'
#' @param gamRslt output from gam model
#' @param iSpec data set specifications (see details for required content)
#' @param analySpec analytical specifications
#' @param base.yr.set vector of years used for baseline period
#' @param doy.set vector of days used to establish sub-annual analyses (see details)
#' @param alpha alpha level for computing confidence intervals
#' @param flow.detrended data generated by detrended.flow.  
#' Default = flow.detrended.
#' @param salinity.detrended data generated by detrended.salinity.  
#' Default = detrended.salinity.
#'
#' @details
#'   iSpec is a list containing information about the date range and
#'   transformations. Specifically, iSpec must include iSpec$yearBegin,
#'   iSpec$yearEnd, iSpec$centerYear corresponding to beginning year of record,
#'   ending year of record and centering year. Also, iSpec must include
#'   iSpec$transform and iSpec$logConst. (See online help for selectData for
#'   more information on these values.)
#'
#'   base.yr.set represent a time periods used to compute the mean. For example,
#'   base.yr.set=c(1999,2000,2001) would compute the GAM predicted mean for
#'   1999-2001. There is no particular limit to the number of years included in
#'   the specification for base.yr.set. For example, a user could specify
#'   c(2001:2002,2004) to use the years 2001, 2002, and 2004, skipping 2003
#'   because 2003 was an abnormal year (particularly wet, particularly dry,
#'   hurricanes, etc.).
#'
#'   base.yr.set must be within the years specified by the range from
#'   iSpec$yearBegin to iSpec$yearEnd (inclusive). If not, this function
#'   defaults to using the first years of record. If base.yr.set is left to its
#'   default values of NA, then the first three years will be used
#'
#'   doy.set represents the days of year for which GAM predictions are made and
#'   used to compute the base.yr mean. For example doy.set= c(15, 46, 75, 106,
#'   136, 167, 197, 228, 259, 289, 320, 350) would result in the 15th of each
#'   month being used in the analysis; whereas doy.set= c(15, 46, 75) would just
#'   use Jan-15, Feb-15, and Mar-15. (Keep in mind that this package uses a 366
#'   day calendar every year such that Mar-1 is always day 61, regardless of
#'   leap year.) If doy.set is left to the default value of NA, then c(15, 46,
#'   75, 106, 136, 167, 197, 228, 259, 289, 320, 350) is used.
#'   
#'   The function baseDay has been added to this package from the smwrBase package.
#'
#' @examples
#' # run analysisOrganizeData function to create the list analySpec
#' dfr <- analysisOrganizeData (dataCensored, report=NA)
#' df        <- dfr[["df"]]
#' analySpec <- dfr[["analySpec"]]
#'
#' # set GAM models to just one model
#' analySpec$gamModels <- list(
#'   list(option=2, name= "Non-linear trend with Seasonality (plus Interactions)",
#'        model= "~ cyear + s(cyear) + s(doy,bs='cc')+ ti(cyear,doy,bs=c('tp','cc'))", deriv=FALSE))
#'
#' # run GAM for a single water quality variable, station and layer
#' gamResult <- gamTest(df, 'tn', 'CB5.4', 'S', analySpec=analySpec)
#'
#' # use gamMeanCI to replicate estimates of change calculated in the above
#' gamMeanCI(gamRslt=gamResult[["gamOutput2"]]$gamRslt,
#'         iSpec=gamResult$iSpec, analySpec=analySpec,
#'         base.yr.set = NA, doy.set = NA, alpha = 0.05)
#'
#' # use gamMeanCI to calculate the mean during from 2004-2005
#' gamMeanCI(gamRslt=gamResult[["gamOutput2"]]$gamRslt,
#'         iSpec=gamResult$iSpec, analySpec=analySpec,
#'         base.yr.set = c(2004:2005), 
#'         doy.set = NA, alpha = 0.05)
#'
#' @return Returns a nest list that includes the base years, doys, period mean
#'   in analyzed units, period mean in observed units, standard error,
#'   confidence intervals, and alpha level. The alpha level corresponds to the
#'   confidence intervals. The first list (gamMeanCI.regular) uses the computed
#'   model to estimate the mean and is applicable for GAM formulas that do not
#'   involve an intervention term. The second list (gamMeanCI.adjusted) performs
#'   computations by projecting the most recent intervention (e.g., the current
#'   lab method) to all time periods.
#'   
#' @export
gamMeanCI <- function(gamRslt
                      , iSpec
                      , analySpec
                      , base.yr.set=NA
                      , doy.set=NA
                      , alpha=0.05
                      , flow.detrended=NA
                      , salinity.detrended=NA) {
  # -----< Change history >--------------------------------------------
  # 24Jun2021: JBH: modified a copy of gamDiff with customizations for calculating
  #                 the mean and confidence interval
  
  # base.yr.set=NA; doy.set=NA; alpha=alpha
  
  # Add pipe
  `%>%` <- dplyr::`%>%`
  
  # Add bindings for global variables
  normPct <- Z <- normD <- flw.wgt <- doy <- flw_sal.sd <- NULL
  
  # unpack ####
  por.rng    <- c(iSpec$yearBegin, iSpec$yearEnd)
  centerYear <- iSpec$centerYear
  transform  <- iSpec$transform
  logConst   <- iSpec$logConst
  gamDiffNumChgYrs <- analySpec$gamDiffNumChgYrs
  
  # Intervention Term ####
  
  # does model include an intervention term 
  intervention <- ifelse (length(grep('intervention',gamRslt$formula  )) == 0, FALSE, TRUE)
  
  # prep intervention list tibble
  intervenList <- dplyr::tibble(iSpec$intervenList) %>%
    dplyr::mutate(intervention = as.character(intervention))
  
  # Hydrologic Term ####
  
  # does model include a hydrologic term (i.e., flw_sal) 
  has.flw_sal <- ifelse (length(grep('flw_sal',gamRslt$formula  )) == 0, FALSE, TRUE)
  
  # if model includes a hydrologic term (i.e., flw_sal) then create flw_sal.sd
  if(has.flw_sal) {
    # populate flw_sal.sd
    if(iSpec$hydroTermSel=="flow") {
      # for "flow", iSpec$hydroTermSel.var will be d* indicating the averaging
      # period associated with the best correlation (i.e., max(abs(cor)))
      # between the dependent variable and the detrended log flow, e.g., d120
      # refers to a 120-day averaging window
      flw_sal.dat <- flow.detrended[[paste0("q",iSpec$usgsGageID,".sum")]][["lowess.sd"]]
      flw_sal.dat <- flw_sal.dat[,c("doy",iSpec$hydroTermSel.var )]
      names(flw_sal.dat)[names(flw_sal.dat) == iSpec$hydroTermSel.var] <- 'flw_sal.sd'
    } else if (iSpec$hydroTermSel=="salinity") {
      # for "salinity", iSpec$hydroTermSel.var will be SAP or BBP indicating the
      # average detrended salinity for "surface and above pycnocline" [SAP] or
      # "bottom and below pycnocline [BBP]. Selection is BBP for dependent
      # variable from B, BP, or BBP; and SAP otherwise
      flw_sal.dat <- salinity.detrended[[paste0(iSpec$stat,".sum")]][["lowess.sd"]]
      flw_sal.dat <- flw_sal.dat[,c("doy",iSpec$hydroTermSel.var )]
      names(flw_sal.dat)[names(flw_sal.dat) == iSpec$hydroTermSel.var] <- 'flw_sal.sd'
    } else {
      return('ERROR in lowess.sd pickup')
    }
  }
  
  # Flow weighting tibble creation ####
  pdatWgt <- dplyr::tibble(normPct = if (has.flw_sal) {analySpec$gamFlw_Sal.Wgt.Perc} else 0.5) %>%
    dplyr::mutate(Z       = stats::qnorm(normPct)
                  , normD   = stats::dnorm(Z)
                  , flw.wgt = normD/sum(normD)) %>%
    dplyr::select(Z, flw.wgt)
  
  # diffType Loop ####  
  
  # diffType="regular"; diffType="adjusted"  
  for(diffType in c("regular","adjusted")) {
    
    # pdat - Prediction table creation - regular ####
    if(diffType=="regular") { 
      
      # if doy.set = NA, then assume doy.set = 15th of each month
      if (is.na(doy.set[1])) {doy.set <- baseDay(as.POSIXct(paste(2000,1:12,15,sep='-')))}
      
      # if base.yr.set = NA, then assume beginning of record
      if (is.na(base.yr.set[1])) {base.yr.set <- c(por.rng[1]:(por.rng[1]+gamDiffNumChgYrs-1))}
      
      Nbase.yr <- length(base.yr.set)   # count years in period
      yr.set   <- base.yr.set           # make yr.set 
      Ndoy     <- length(doy.set)       # count predictions per year
      Nbase    <- Ndoy*Nbase.yr         # calculate total predictions in base period
      
      # create prediction data set (one row for each Nbase)
      pdat <- dplyr::tibble(expand.grid(doy.set,yr.set))  %>%  # make all combinations of doy.set & yr.set    
        dplyr::rename("doy" = "Var1"
                      ,  "year" = "Var2") %>%
        dplyr::mutate(bl = (year <= base.yr.set[Nbase.yr])         # TRUE for years in baseline (all should be true)
                      ,  cyear  = (year + (doy-1)/366) - centerYear   # compute cyear (centered year)
                      ,  month  = lubridate::month(as.Date(doy, origin = "1999-12-31"))
                      ,  day    = lubridate::day  (as.Date(doy, origin = "1999-12-31"))
                      ,  date   = as.POSIXct(paste(year, month, day,sep='-'))
                      ,  intervention = intervenList$intervention[findInterval(date, intervenList$beginDate)]
                      ,  intervention = factor(intervention, levels = intervenList$intervention)
                      ,  rowID = seq.int(nrow(.)))
      
      # pdat - Expansion for hydrologic term ####
      if(has.flw_sal) {
        pdat <- pdat %>%
          dplyr::mutate(flw_sal = 0) %>%
          dplyr::left_join(flw_sal.dat, by="doy") %>%
          dplyr::arrange(date)
      } else {
        pdat <- pdat %>%
          dplyr::mutate(flw_sal = NA_real_
                        ,  flw_sal.sd = NA_real_)
      }
      
      # Sort columns  
      pdat <- pdat %>%
        dplyr::relocate("rowID","date","year","cyear","doy")
      
      # expand prediction data set to include additional variables (excluding dependent variable and "gamK*" )
      indVar <- setdiff (all.vars(gamRslt$formula), c(iSpec$dep, names(pdat)))
      indVar <- indVar[-grep("^gamK", indVar)]
      pdat[,indVar] <- 0
      
      # pdat - Prediction table creation - adjustment ####
      # "adjust" prediction table pdat to use last intervention value for all calculations
    } else if (diffType=="adjusted") {
      pdat$intervention <- pdat$intervention[length(pdat$intervention)]
    }      
    
    # pdatLong - Creation ####
    # Use pdat with a downselected number of columns for merging with pdatWgt;
    # in the merge of pdatWgt and pdatLong (each row of pdat is repeated for
    # each record in pdatWgt, then goes to next row of pdat); flw_sal based on z
    # stat and sd
    pdatLong <- pdat %>%
      dplyr::select(c("rowID"
                      , "cyear"
                      , "doy"
                      , "bl"
                      , "intervention"
                      , "flw_sal"
                      , "flw_sal.sd"
                      , dplyr::all_of(indVar))) 
    
    pdatLong <- merge(pdatWgt, pdatLong) %>%
      dplyr::mutate(flw_sal = Z * flw_sal.sd)
    
    # Begin mean calculations ####
    {
      # Create averaging matrices: xa and avg.per.mat
      xa <- c(rep(1/Nbase,Nbase*nrow(pdatWgt)))  
      avg.per.mat <- matrix(xa,nrow=1,ncol=(Nbase)*nrow(pdatWgt), byrow=TRUE)
      
      # Apply flow weighting to the averaging matrix 
      avg.per.mat <- avg.per.mat * t(pdatLong$flw.wgt)
      
      # Construct difference matrix
      diff.mat <- c(1)
      
      # Extract coefficients (number of terms depends on complexity of GAM formula)
      beta    <- gamRslt$coefficients        # coefficients vector
      VCmat   <- gamRslt$Vp                  # variance-covariance matrix of coefficents
      
      # Begin calculations to compute differences ####
      # extract matrix of linear predicters
      Xpc     <- predict(gamRslt,newdata=pdatLong,type="lpmatrix")
      
      # Compute predictions based on linear predictors (Nrow x 1 matrix)
      pdep    <- Xpc %*% beta # equivalent to "predict(gamRslt,newdata=pdatLong)"
      
      # Calc. average baseline 
      period.avg <- avg.per.mat %*% pdep
      
      # Calc standard errors and confidence intervals on predictions
      xpd       <- diff.mat %*% avg.per.mat %*% Xpc # premultiply linear predictors by averaging and differencing matrices.
      diff.est  <- xpd %*% beta                     # compute estimate of difference
      diff.se   <- sqrt(xpd %*% VCmat %*% t(xpd))   # compute Std. Err. by usual rules
      
      # compute CI for difference
      halpha    <- alpha/2
      diff.ci   <- c(diff.est - qnorm(1-halpha) * diff.se
                     , diff.est + qnorm(1-halpha) *diff.se)
      
      # back transform mean
      per.mn.obs <- if(transform) exp(period.avg) - logConst else period.avg
    }
    
    # pack up results ####
    gamMeanCI.tmp <- list(base.yr    = base.yr.set,
                          base.plot  = mean(range(pdat$date[pdat$bl])),
                          doys       = doy.set,
                          per.mn     = as.vector(period.avg),
                          per.mn.obs = as.vector(per.mn.obs),
                          diff.se    = diff.se,
                          diff.ci    = diff.ci,
                          alpha      = alpha)
    
    # distinction for "regular" and "adjusted" results
    if(diffType=="regular") {
      gamMeanCI.regular <- gamMeanCI.tmp
    } else if(diffType=="adjusted") {
      gamMeanCI.adjusted <- gamMeanCI.tmp
    }
    
  }
  
  gamMeanCI.return <- list(gamMeanCI.regular=gamMeanCI.regular
                           , gamMeanCI.adjusted=gamMeanCI.adjusted)
  return(gamMeanCI.return)
  
}
